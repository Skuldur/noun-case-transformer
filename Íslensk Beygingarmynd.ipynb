{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Add masking to all padding so it's not taken into account when doing calculations\n",
    "* Add special start and end tokens like CLS and SEP so we know where the end of the generation is\n",
    "* Try removing Decoder again\n",
    "* Mask out padding in loss function\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import combinations\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SHsnid.csv', names=[\"Word\", \"ID\", \"Gender\", \"???\", \"Beyging\", \"Fall\"], sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.loc[df.Word == 'góður']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df = df.loc[df.Gender.isin(['hk', 'kvk', 'kk'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = df[[\"Word\", \"Beyging\", \"Fall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Fall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.Fall == 'ÞFET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_articles = train_df.loc[train_df.Fall.isin(['ÞFET', 'NFET', 'EFET', 'ÞGFET', 'ÞFFT', 'ÞGFFT', 'NFFT', 'EFFT', ])]\n",
    "articles = train_df.loc[train_df.Fall.isin(['ÞFETgr', 'NFETgr', 'EFETgr', 'ÞGFETgr', 'ÞFFTgr', 'ÞGFFTgr', 'NFFTgr', 'EFFTgr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.replace(['ÞFETgr', 'NFETgr', 'EFETgr', 'ÞGFETgr', 'ÞFFTgr', 'ÞGFFTgr', 'NFFTgr', 'EFFTgr'], ['ÞFET', 'NFET', 'EFET', 'ÞGFET', 'ÞFFT', 'ÞGFFT', 'NFFT', 'EFFT', ], inplace=True)\n",
    "\n",
    "print(no_articles.loc[train_df.Word == 'hestur'])\n",
    "print(articles.loc[train_df.Word == 'hestur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "declension_mapping = {}\n",
    "\n",
    "for index, row in no_articles.iterrows():\n",
    "    if not declension_mapping.get(row['Word'].lower()):\n",
    "        declension_mapping[row['Word'].lower()] = {}\n",
    "        \n",
    "    declension_mapping[row['Word'].lower()][row['Fall'].lower()] = row['Beyging'].lower()\n",
    "    \n",
    "for index, row in articles.iterrows():\n",
    "    if not declension_mapping.get(row['Word'].lower() + 'gr'):\n",
    "        declension_mapping[row['Word'].lower() +'gr'] = {}\n",
    "        \n",
    "    declension_mapping[row['Word'].lower()+'gr'][row['Fall'].lower()] = row['Beyging'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words_data = []\n",
    "output_words_data = []\n",
    "source_declension = []\n",
    "target_declension = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for key, word in declension_mapping.items():\n",
    "    declension_combs = list(combinations(word.keys(), 2))\n",
    "    word_combs = list(combinations(word.values(), 2))\n",
    "    \n",
    "    input_words_data += [w[0] for w in word_combs]\n",
    "    output_words_data += [w[1] for w in word_combs]\n",
    "    source_declension += [d[0] for d in declension_combs]\n",
    "    target_declension += [d[1] for d in declension_combs]\n",
    "    \n",
    "    #idx += 1\n",
    "    \n",
    "    #if idx > 5000:\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for w in input_words_data:\n",
    "    for ch in list(w):\n",
    "        vocab.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(vocab))\n",
    "vocab = ['<pad>', '<BEG>', '<END>'] + vocab\n",
    "declensions = ['nfet', 'þfet', 'þgfet', 'efet', 'nfft', 'þfft', 'þgfft',  'efft']\n",
    "\n",
    "ch2idx = {ch: idx for idx, ch in enumerate(vocab)}\n",
    "idx2ch = {idx: ch for idx, ch in enumerate(vocab)}\n",
    "decl2idx = {d: idx for idx, d in enumerate(declensions)}\n",
    "idx2decl = {idx: d for idx, d in enumerate(declensions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the character and declension mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./ch2idx.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(ch2idx, fp, ensure_ascii=False)\n",
    "    \n",
    "with open('./decl2idx.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(decl2idx, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change from characters to indices and pad all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words_data = [['<BEG>']+list(w)+['<END>'] for w in input_words_data]\n",
    "output_words_data = [['<BEG>']+list(w)+['<END>'] for w in output_words_data]\n",
    "\n",
    "input_words_data = [[ch2idx[ch] for ch in w] for w in input_words_data]\n",
    "output_words_data = [[ch2idx[ch] for ch in w] for w in output_words_data]\n",
    "\n",
    "maxlen=32\n",
    "\n",
    "input_words_data = pad_sequences(input_words_data, maxlen=maxlen, padding='post', value=0)\n",
    "output_words_data = pad_sequences(output_words_data, maxlen=maxlen, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclensionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_words, output_words, src_decl, tgt_decl, ch2idx, decl2idx):\n",
    "        super(DeclensionDataset, self).__init__()\n",
    "        \n",
    "        self.input = input_words\n",
    "        self.output = output_words\n",
    "        self.src_decls = src_decl\n",
    "        self.tgt_decls = tgt_decl\n",
    "        self.vocab = ch2idx\n",
    "        self.decl_vocab = decl2idx\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        word = self.input[index]\n",
    "        \n",
    "        src_decl = self.decl_vocab[self.src_decls[index]]\n",
    "        tgt_decl = self.decl_vocab[self.tgt_decls[index]]\n",
    "        \n",
    "        output = self.output[index]\n",
    "        \n",
    "        return torch.LongTensor(word), torch.LongTensor(output), src_decl, tgt_decl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    " \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "# shuffle the data but keep it consistent over all four datasets\n",
    "indices = [i for i in range(len(input_words_data))]\n",
    "indices = sample(indices, len(indices))\n",
    "split = int(len(indices) * 0.9)\n",
    "\n",
    "train_input = [input_words_data[i] for i in indices[:split]]\n",
    "train_output = [output_words_data[i] for i in indices[:split]]\n",
    "train_src = [source_declension[i] for i in indices[:split]]\n",
    "train_tgt = [target_declension[i] for i in indices[:split]]\n",
    "\n",
    "val_input = [input_words_data[i] for i in indices[split:]]\n",
    "val_output = [output_words_data[i] for i in indices[split:]]\n",
    "val_src = [source_declension[i] for i in indices[split:]]\n",
    "val_tgt = [target_declension[i] for i in indices[split:]]\n",
    "\n",
    "train_dataset = DeclensionDataset(train_input, train_output,train_src, train_tgt, ch2idx, decl2idx)\n",
    "val_dataset = DeclensionDataset(val_input, val_output, val_src, val_tgt, ch2idx, decl2idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True) #collate_fn=pad_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256) #collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetNetwork(nn.Module):\n",
    "    def __init__(self, ninput, nhidden=512, noutput=512, maxlen=32, nembed=128):\n",
    "        super(TargetNetwork, self).__init__()\n",
    "        \n",
    "        self.tgt_dec_emb = nn.Embedding(ninput, nembed)\n",
    "        \n",
    "    def forward(self, tgt_dec):\n",
    "        x = self.tgt_dec_emb(tgt_dec)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class TransformerNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, char_vocab, embedding_len=128, nheads=12, num_layers=12, activation='gelu', dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.char_emb = nn.Embedding(char_vocab, embedding_len)\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(embedding_len, dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_len, nhead=nheads, activation=activation)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, words):\n",
    "        # Add padding mask\n",
    "        padding_mask = (words == 0).T\n",
    "        \n",
    "        word_embed = self.char_emb(words)\n",
    "        word_embed = self.pos_encoder(word_embed)\n",
    "        \n",
    "        out = self.transformer_encoder(word_embed, src_key_padding_mask=padding_mask)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "class DeclensionTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, char_vocab, num_declensions, max_len=32, nheads=12, num_layers=6, embedding_len=516, dim_feedforward=2048, dropout=0.1, activation='gelu'):\n",
    "        super(DeclensionTransformer, self).__init__()\n",
    "        self.transformer_network = TransformerNetwork(char_vocab, embedding_len, nheads, num_layers)\n",
    "        \n",
    "        self.target_network = TargetNetwork(num_declensions, noutput=embedding_len)\n",
    "        self.source_network = TargetNetwork(num_declensions, noutput=embedding_len)\n",
    "        \n",
    "        self.linear1 = nn.Linear(772, dim_feedforward)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, char_vocab)\n",
    "        self.linear3 = nn.Linear(embedding_len, char_vocab)\n",
    "        \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "        \n",
    "        \n",
    "    def forward(self, word_input, src_dec, tgt_dec):\n",
    "        words_encoded = self.transformer_network(word_input)\n",
    "        tgt_encoded = self.target_network(tgt_dec)\n",
    "        src_encoded = self.source_network(src_dec)\n",
    "\n",
    "        out = torch.cat((words_encoded, tgt_encoded, src_encoded), 2)\n",
    "        \n",
    "        out = self.linear2(self.dropout1(self.relu(self.linear1(out))))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = 'hestur'\n",
    "print(len(vocab))\n",
    "\n",
    "model = DeclensionTransformer(len(vocab), len(declensions))\n",
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "print('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a loss function with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedCrossEntropyLoss(nn.Module):\n",
    "    \n",
    "    \n",
    "    def forward(self, preds, target):\n",
    "\n",
    "        total_loss = 0.\n",
    "        zeros = torch.zeros(target.size(0)).to(device)\n",
    "        \n",
    "        mask = (target != 0).float()\n",
    "        \n",
    "        loss = F.cross_entropy(preds, target, reduction='none')\n",
    "        \n",
    "        loss = loss * mask.float()\n",
    "        \n",
    "        return loss.sum() / torch.nonzero(loss).size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NestedCrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5,weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-4, pct_start=0.3, steps_per_epoch=len(train_loader), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def num_correct_preds(preds, target):\n",
    "    num_words = len(preds)\n",
    "    _, predicted = torch.max(preds, 1)\n",
    "    correct = 0.\n",
    "    \n",
    "    #print(predicted.shape)\n",
    "    target[target==0] = -1\n",
    "    \n",
    "    correct = ((predicted == target).sum()).item()\n",
    "    \n",
    "    \"\"\"    #correct = (predicted == target).sum().item() / float(target.size(0))\n",
    "    for idx in range(num_words):\n",
    "        # If target is padding we ignore it\n",
    "        if target[idx] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if predicted[idx] == target[idx]:\n",
    "                correct += 1\"\"\"\n",
    "            \n",
    "    \n",
    "    return correct / target[target!=-1].size(0)\n",
    "\n",
    "def train(epochs, scheduler, optimizer, model):\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        running_loss = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        # use dropouts and batchnorms\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            word_input, output, src_dec, tgt_dec = batch\n",
    "            \n",
    "            word_input = torch.LongTensor(word_input).t()\n",
    "            src_dec = torch.LongTensor([[dec]*word_input.shape[0] for dec in src_dec]).t()\n",
    "            tgt_dec = torch.LongTensor([[dec]*word_input.shape[0] for dec in tgt_dec]).t()\n",
    "            target = torch.LongTensor(output).t().contiguous().view(-1)\n",
    "            \n",
    "            word_input = word_input.to(device)\n",
    "            src_dec = src_dec.to(device)\n",
    "            tgt_dec = tgt_dec.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            outputs = model(word_input, src_dec,  tgt_dec)\n",
    "            \n",
    "            loss = criterion(outputs.view(-1, len(vocab)), target)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            curr_correct = num_correct_preds(outputs.view(-1, len(vocab)), target)\n",
    "            n_correct += curr_correct\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_acc = 100. * n_correct / (len(train_loader))\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        n_val_correct = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # disable batchnorm and dropouts\n",
    "        model.eval()\n",
    "        # don't calculate gradient\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                word_input, output, src_dec, tgt_dec = batch\n",
    "\n",
    "                word_input = torch.LongTensor(word_input).t()\n",
    "                src_dec = torch.LongTensor([[dec]*word_input.shape[0] for dec in src_dec]).t()\n",
    "                tgt_dec = torch.LongTensor([[dec]*word_input.shape[0] for dec in tgt_dec]).t()\n",
    "                target = torch.LongTensor(output).t().contiguous().view(-1)\n",
    "\n",
    "                word_input = word_input.to(device)\n",
    "                src_dec = src_dec.to(device)\n",
    "                tgt_dec = tgt_dec.to(device)\n",
    "                target = target.to(device)\n",
    "                \n",
    "                outputs = model.forward(word_input, src_dec, tgt_dec)\n",
    "                \n",
    "                val_loss = criterion(outputs.view(-1, len(vocab)), target).item()\n",
    "                \n",
    "                n_val_correct += num_correct_preds(outputs.view(-1, len(vocab)), target)\n",
    "                  \n",
    "        val_acc = 100. * n_val_correct / (len(val_loader))\n",
    "\n",
    "        print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss:  %.5f, Validation Loss:  %.5f - %s seconds' \n",
    "              % (epoch, train_acc, val_acc, train_loss, val_loss, time.time() - start))\n",
    "        \n",
    "train(5, scheduler, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    './models/icelandic_declension_only_weights.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./ch2idx_final_99.8%.json', encoding='utf-8') as f:\n",
    "    ch2idx = json.load(f)\n",
    "\n",
    "with open('./decl2idx_final_99.8%.json', encoding='utf-8') as f:\n",
    "    decl2idx = json.load(f)\n",
    "    \n",
    "idx2ch = {v:k for k,v in ch2idx.items()}\n",
    "idx2decl = {v:k for k,v in decl2idx.items()}\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = DeclensionTransformer(len(ch2idx), len(decl2idx))\n",
    "model.to(device)\n",
    "checkpoint = torch.load('./models/icelandic_declension_final-99.79%.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 32\n",
    "\n",
    "def predict(word, src, targets):\n",
    "    print(word)\n",
    "    #print(idx2decl[src], ':', word)\n",
    "    \n",
    "    word = ['<BEG>'] + list(word) +  ['<END>']\n",
    "    word = word + ['<pad>']*(32-len(word))\n",
    "    \n",
    "    word = torch.LongTensor([ch2idx[c] for c in word])\n",
    "    word = word.to(device)[None].t()\n",
    "    \n",
    "    if type(targets) != list:\n",
    "        targets = [targets]\n",
    "        \n",
    "    src_padded = torch.LongTensor([src]*maxlen).to(device)[None].t()\n",
    "    \n",
    "    for tgt in targets:\n",
    "        #word = [ch2idx[ch] for ch in word]\n",
    "        #print([idx2ch[idx] for idx in word.tolist()])\n",
    "\n",
    "        #print(word.shape)\n",
    "        #word = torch.LongTensor(word + [0] * (maxlen - len(word))).to(device)[None]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        tgt_padded = torch.LongTensor([tgt]*maxlen).to(device)[None].t()\n",
    "\n",
    "        pred = model(word, src_padded, tgt_padded)\n",
    "        #print(pred.argmax(2).tolist())\n",
    "        output = [idx2ch[idx[0]] for idx in pred.argmax(2).tolist()]\n",
    "        output_word = ''.join(output[1:output.index('<END>')])\n",
    "        print(idx2decl[tgt], ':', output_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#word, _, src, tgt = train_dataset[0]\n",
    "\n",
    "#print(src, tgt)\n",
    "\n",
    "words = ['herra', 'hnetusmjör']\n",
    "\n",
    "for word in words:\n",
    "    predict(word, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
